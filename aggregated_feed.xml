<rss version="2.0">
  <channel>
    <title>RSS Aggregator Feed</title>
    <link>https://hitem.github.io/rss-aggregator/aggregated_feed.xml</link>
    <description>An aggregated feed of Microsoft blogs</description>
    <lastBuildDate>Thu, 14 Aug 2025 19:08:11 GMT</lastBuildDate>
    <item>
      <title>Investigating M365 Copilot Activity with Sentinel &amp; Defender XDR</title>
      <link>https://techcommunity.microsoft.com/t5/microsoft-security-community/investigating-m365-copilot-activity-with-sentinel-defender-xdr/ba-p/4442641</link>
      <pubDate>Thu, 14 Aug 2025 18:58:58 GMT</pubDate>
      <guid isPermaLink="false">https://techcommunity.microsoft.com/t5/microsoft-security-community/investigating-m365-copilot-activity-with-sentinel-defender-xdr/ba-p/4442641</guid>
      <description>As organizations embrace AI-powered tools like Microsoft Copilot, ChatGPT, and other generative assistants, one thing becomes immediately clear: AI is only as trustworthy as the data it can see. These systems are increasingly woven into everyday workstreams, surfacing insights, drafting content, and answering questions based on enterprise data signals. Yet behind the magic lies a new security frontier: making sure AI only accesses the right data, the right way, at the right time.
That&#8217;s where Data Security Posture Management (DSPM) comes into play. Data Security Posture Management (DSPM) for A...</description>
    </item>
  </channel>
</rss>
